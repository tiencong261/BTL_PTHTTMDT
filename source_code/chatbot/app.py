import faiss
import json
from sentence_transformers import SentenceTransformer
from flask import Flask, request, jsonify
import google.generativeai as genai
from flask_cors import CORS, cross_origin
import os
from classifier import load_model, predict, TransformerClassifier
from productQuery import productsResponse

os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

app = Flask(__name__)
CORS(app)  # Cho ph√©p CORS ƒë·ªÉ frontend truy c·∫≠p API

# üîπ Load API Key c·ªßa Gemini
genai.configure(api_key="AIzaSyAmLesw2keGhIrZPMEyYJUs1PUqIidIWFU")
model = genai.GenerativeModel("gemini-2.0-flash")
classify_model = load_model("training/model.pkl")

# L·ªãch s·ª≠ tr√≤ chuy·ªán (t·ªëi ƒëa 5 tin nh·∫Øn)
chat_history = []

with open("data/store.json", "r", encoding="utf-8") as f:
    intro_info = json.load(f)

# Load d·ªØ li·ªáu t·ª´ JSON
def load_terms(filename="data/terms.json"):
    with open(filename, "r", encoding="utf-8") as file:
        return json.load(file)

model_emb = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")

def classify_question(user_input):
    text = user_input
    result = predict(text, classify_model)
    print(result)
    return result

# T·∫°o FAISS Index
def build_faiss_index(data):
    texts = [entry["title"] + " - " + entry["content"] for entry in data]
    embeddings = model_emb.encode(texts, convert_to_numpy=True)

    # T·∫°o FAISS index
    index = faiss.IndexFlatL2(embeddings.shape[1])
    index.add(embeddings)
    
    return index, texts, data

# T√¨m ki·∫øm ƒëi·ªÅu kho·∫£n li√™n quan
def search_terms(query, index, texts, data, top_k=1):
    query_embedding = model_emb.encode([query], convert_to_numpy=True)
    _, indices = index.search(query_embedding, top_k)

    results = []
    for idx in indices[0]:
        results.append(data[idx])  # L·∫•y n·ªôi dung t·ª´ d·ªØ li·ªáu g·ªëc

    return results


@app.route("/chat", methods=["POST"])
@cross_origin()
def chat():
    global chat_history  # S·ª≠ d·ª•ng bi·∫øn to√†n c·ª•c ƒë·ªÉ l∆∞u l·ªãch s·ª≠ tr√≤ chuy·ªán
    data = request.get_json()
    user_message = data.get("message", "")

    if not user_message:
        return jsonify({"error": "No message provided"}), 400
    
    category = classify_question(user_message)
    
    # Th√™m tin nh·∫Øn m·ªõi v√†o l·ªãch s·ª≠
    chat_history.append(f"Ng∆∞·ªùi d√πng: {user_message}")
    
    # N·∫øu l·ªãch s·ª≠ v∆∞·ª£t qu√° 5 tin nh·∫Øn, x√≥a tin nh·∫Øn c≈© nh·∫•t
    if len(chat_history) > 4:
        chat_history.pop(0)
    # Gh√©p l·ªãch s·ª≠ tin nh·∫Øn v√†o prompt
    history_context = "\n".join(chat_history)
    
    if category == "product":
        try:
            response = productsResponse(history_context, user_message)
            print(response)
            final_prompt = f"L·ªãch s·ª≠ tr√≤ chuy·ªán:\n{history_context}\nC√¢u h·ªèi c·ªßa kh√°ch h√†ng: {user_message}\n Th√¥ng tin t√¨m ƒë∆∞·ª£c: {response}\nTr·∫£ l·ªùi m·ªôt c√°ch th√¢n thi·ªán nh∆∞ m·ªôt nh√¢n vi√™n b√°n h√†ng."
            response = model.generate_content(final_prompt)
            chat_history.append(f"Bot: {response.text.replace("\n", "<br>")}")
            return jsonify({"reply": response.text.replace("\n", "<br>")})
        except Exception as e:
            return jsonify({"error": str(e)}), 500
    elif category == "store_info":
        context = (
            f" T√™n c·ª≠a h√†ng: {intro_info['name']}\n"
            f" ƒê·ªãa ch·ªâ: {intro_info['address']}\n"
            f" Th·ªùi gian m·ªü c·ª≠a: {intro_info['open_hours']}\n"
            f" Li√™n h·ªá: {intro_info['contact']}\n"
            f" {intro_info['description']}"
        )
        final_prompt = f"L·ªãch s·ª≠ tr√≤ chuy·ªán:\n{history_context}\nC√¢u h·ªèi c·ªßa kh√°ch h√†ng: {user_message}\n Th√¥ng tin t√¨m ƒë∆∞·ª£c: {context}\nTr·∫£ l·ªùi m·ªôt c√°ch th√¢n thi·ªán nh∆∞ m·ªôt nh√¢n vi√™n b√°n h√†ng."
        response = model.generate_content(final_prompt)
        chat_history.append(f"Bot: {response.text.replace("\n", "<br>")}")
        return jsonify({"reply": response.text.replace("\n", "<br>")})
    
    elif category == "else":
        final_prompt = f"L·ªãch s·ª≠ tr√≤ chuy·ªán:\n{history_context}\nC√¢u h·ªèi c·ªßa kh√°ch h√†ng: {user_message}\n H√£y tr·∫£ l·ªùi h·ªç nh∆∞ l√† m·ªôt ng∆∞·ªùi b√°n h√†ng vui v·∫ª v√† th√¢n thi·ªán h√†i h∆∞·ªõc."
        response = model.generate_content(final_prompt)
        chat_history.append(f"Bot: {response.text.replace("\n", "<br>")}")
        return jsonify({"reply": response.text.replace("\n", "<br>")})
    
    elif category == "terms":
        context = search_terms(user_message, faiss_index, faiss_texts, faiss_data)
        final_prompt = f"L·ªãch s·ª≠ tr√≤ chuy·ªán:\n{history_context}\nC√¢u h·ªèi c·ªßa kh√°ch h√†ng: {user_message}\n Th√¥ng tin t√¨m ƒë∆∞·ª£c: {context}\nTr·∫£ l·ªùi m·ªôt c√°ch th√¢n thi·ªán nh∆∞ m·ªôt nh√¢n vi√™n b√°n h√†ng."
        response = model.generate_content(final_prompt)
        chat_history.append(f"Bot: {response.text.replace("\n", "<br>")}")
        return jsonify({"reply": response.text.replace("\n", "<br>")})
    
    if len(chat_history) > 4:
        chat_history.pop(0)

if __name__ == "__main__":
    data = load_terms()
    faiss_index, faiss_texts, faiss_data = build_faiss_index(data)
    app.run(debug=True, port=5001)
